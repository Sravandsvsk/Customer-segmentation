# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1emSmzQOjP-6br79FnyAx6I1fB1wS7Su1
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler

# Load the dataset
@st.cache_data
def load_data():
    data = pd.read_excel('marketing_campaign1.xlsx')
    return data.copy()

data = load_data()

# Preprocess the data (Standardization)
@st.cache_data
def preprocess_data(data):
    features = data[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts']].dropna()
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    return features, scaled_features

features, scaled_features = preprocess_data(data)

# Title and Description
st.title("Advanced Customer Segmentation and Personality Analysis")
st.write("""
This app allows you to explore clustering results interactively by selecting different algorithms and customizing their parameters.
You can also use PCA for dimensionality reduction to visualize clustering better.
""")

# Sidebar for clustering options
st.sidebar.header("Clustering Options")

# PCA Toggle
apply_pca = st.sidebar.checkbox("Apply PCA", value=False)
if apply_pca:
    n_components = st.sidebar.slider("Number of PCA Components", min_value=2, max_value=4, value=2)
    pca = PCA(n_components=n_components)
    pca_features = pca.fit_transform(scaled_features)
    st.write("Explained Variance Ratio:", pca.explained_variance_ratio_)
    features_to_cluster = pca_features
else:
    features_to_cluster = scaled_features

# Dropdown menu for selecting algorithms
algorithm = st.sidebar.selectbox(
    "Select Clustering Algorithm",
    ["KMeans", "DBSCAN", "Agglomerative Clustering"]
)

# Show appropriate inputs based on algorithm selection
if algorithm == "KMeans":
    num_clusters = st.sidebar.slider("Number of Clusters (k)", min_value=2, max_value=10, value=4)
elif algorithm == "DBSCAN":
    eps = st.sidebar.slider("Epsilon (eps)", min_value=0.1, max_value=5.0, value=0.5, step=0.1)
    min_samples = st.sidebar.slider("Minimum Samples", min_value=1, max_value=10, value=5)
elif algorithm == "Agglomerative Clustering":
    num_clusters = st.sidebar.slider("Number of Clusters", min_value=2, max_value=10, value=4)
    linkage = st.sidebar.selectbox("Linkage", ["ward", "complete", "average", "single"])

# Perform clustering
st.subheader("Clustering Results")
if st.button("Run Clustering"):
    if algorithm == "KMeans":
        model = KMeans(n_clusters=num_clusters, random_state=42)
        labels = model.fit_predict(features_to_cluster)
    elif algorithm == "DBSCAN":
        model = DBSCAN(eps=eps, min_samples=min_samples)
        labels = model.fit_predict(features_to_cluster)
    elif algorithm == "Agglomerative Clustering":
        model = AgglomerativeClustering(n_clusters=num_clusters, linkage=linkage)
        labels = model.fit_predict(features_to_cluster)

    # Add cluster labels to the dataset
    features['Cluster'] = labels

    # Visualize clusters
    st.write("Cluster Visualization")
    plt.scatter(
        features_to_cluster[:, 0], features_to_cluster[:, 1],
        c=labels, cmap='viridis', s=50, alpha=0.7
    )
    plt.xlabel("Component 1" if apply_pca else features.columns[0])
    plt.ylabel("Component 2" if apply_pca else features.columns[1])
    plt.title(f"Clusters using {algorithm}")
    st.pyplot(plt)

    # Display the labeled data
    st.write("Cluster Assignments")
    st.dataframe(features[['MntWines', 'MntFruits', 'Cluster']])

# Conclusion
st.write("""
### Explore different algorithms and parameters to understand their impact on clustering results!
Use PCA to simplify and visualize high-dimensional data effectively.
""")